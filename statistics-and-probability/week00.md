## Statistical Thinking for Data Science

Statistics derives knowledge from *samples* regarding a *population* by
carefully conducting data collection and data analysis.

When analyzing data, we must ask, "can an observed difference be explained
purely by chance? Can we observe differences in outcomes even if a treatment
or intervention has *no* actual effects?"

A treatment can be thought of as an input. As researchers, we want to study its
true effects on a given outcome. At the same time, we know that there are other
random factors that also affect the outcome. How do we carry out statistical
inference so that we can estimate the extent of the random effects and use that
to establish the size of the *true* effect? In other words, how do we evaluate
the observed effect so that we can say whether it is likely to occur purely by
chance? If this is "very unlikely," we say the result is statistically
significant. That is, the effect is so large that we do not think that it can
be explained purely by chance and we believe that part of the observed effect
is due to the treatment.

Statistics establishes statistical significance of observed signal by studying
randomness.

How do we derive answers from data? Data is generated by a "data generating
process." In some studies, there is control over how the data is generated.
More often, however, there is not. Statisticians and data scientists make
assumptions about the data generating process, which guide the analyses that
are performed. The data is then fed through the analysis process to derive
answers to our questions.

If assumptions are not valid, then the answers become invalid. When this
happens, we need to determine which assumptions were invalid and develop
revised ones. This may lead to revisions in the analysis plan, which should,
hopefully, result in better answers.

The validity of results depend on the validity of the assumptions regarding the
data generating processes. This assumptions can be related to:

* sampling
* randomization
* measurement
* independence
* etc.

## Numerical Data I Simple Visualization and Summaries

Data are numbers with context. For example, the value $70$ might refer to
temerature, age, weights, time, etc. When data are measured on individuals,
individuals are the unit of measurement of that data set. In other data sets,
the unit of measurement can be objects, dates, time units, events, etc.

On an individual, we may have data several characteristics, including:

* gender
* age
* education
* income
* answers to specific survey questions

On the *unit of measurement*, an individual in this example, we observe a set
of variables and we observe those same set of variables on other individuals.
Variables are the focus of analyses because we want to study the variation of
variables to gauge trends and randomness and the extent of variability in
particular variables to generate knowledge of a population.

Variables can be of different types. There are three main types.

* categorical: the values represent different categories or classes and they do
  not have an ordering or arithmetic meaning
* quantitative: the values represent numerical quantities that can be ordered
  and averaged
* ordinal: the values represent *ordered* categories that do not have
  arithmetic meaning (they cannot be averaged, for example)

Statistics are numerical summaries of data. For example, we can calculate
frequencies on a categorical variable's values. Statistics do not tell the
whole story, but they are useful and meaningful.

We can display counts (or frequencies) of the observed occurrences for each
level in categorical variables. With quantitative data, we can count
occurrences *within intervals*. In either case, the values can be converted to
percentages or proportions.

Bar plots can be used for visualizing categorical data. Histograms are useful
for quantitative data. In a histogram, the height of each bar is called the
"density." Multiplying the density by the width of its corresponding bar
results in the proportion.

There are lots of other visualization options that will be discussed in a
future lecture.

## Numerical Data II Simple Visualization and Summaries

With numerical summaries, we are often interested in the "center of variation."
This is the value around which most of the data is distributed around. There
are two ways to summarize this: mean and median.

The mean is the numerical average and the median is the midpoint. The mean is
sensitive to outliers; the median is not. When there are outliers, as is often
the case with wage data, for example, distributions are skewed. Wage data is
usually right skewed, meaning that the outliers appear on the right side of
the distribution&mdash;the highest values. In this case, the mean will always
be larger than the median.

It is also important to summarize variation. There are two statistics we can
use for this: variance and standard deviation. The standard deviation is simply
the square root of the variance.
